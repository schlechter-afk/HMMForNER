{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, states, observations):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.start_probabilities = np.zeros(len(states))\n",
    "        self.transition_probabilities = np.zeros((len(states), len(states)))\n",
    "        self.emission_probabilities = np.zeros((len(states), len(observations)))\n",
    "\n",
    "        self.state_index = {state: i for i, state in enumerate(states)}\n",
    "        self.observation_index = {obs: i for i, obs in enumerate(observations)}\n",
    "\n",
    "    def compute_start_probabilities(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            start_state = sequence[0][1]  # The tag of the first token\n",
    "            self.start_probabilities[self.state_index[start_state]] += 1\n",
    "        self.start_probabilities /= np.sum(self.start_probabilities)\n",
    "\n",
    "    def compute_transition_probabilities(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            for i in range(len(sequence) - 1):\n",
    "                current_state = sequence[i][1]\n",
    "                next_state = sequence[i + 1][1]\n",
    "                self.transition_probabilities[self.state_index[current_state], self.state_index[next_state]] += 1\n",
    "\n",
    "        for i in range(len(self.states)):\n",
    "            if(np.sum(self.transition_probabilities[i])==0):\n",
    "                continue\n",
    "            self.transition_probabilities[i] /= np.sum(self.transition_probabilities[i])\n",
    "\n",
    "    def compute_emission_probabilities(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            for token, state in sequence:\n",
    "                self.emission_probabilities[self.state_index[state], self.observation_index[token]] += 1\n",
    "\n",
    "        for i in range(len(self.states)):\n",
    "            if(np.sum(self.emission_probabilities[i])==0):\n",
    "                continue\n",
    "            self.emission_probabilities[i] /= np.sum(self.emission_probabilities[i])\n",
    "\n",
    "    def viterbi_algorithm(self, obs):\n",
    "        viterbi_table = [[0.0 for _ in range(len(self.states))] for _ in range(len(obs))]\n",
    "        backpointer = [[0 for _ in range(len(self.states))] for _ in range(len(obs))]\n",
    "\n",
    "        for t in range(len(obs)):\n",
    "            for s in range(len(self.states)):\n",
    "                if t == 0:\n",
    "                    viterbi_table[t][s] = self.start_probabilities[s] * self.emission_probabilities[s][obs[t]]\n",
    "                else:\n",
    "                    max_prob = -1\n",
    "                    max_backpointer = -1\n",
    "\n",
    "                    for s_prime in range(len(self.states)):\n",
    "                        prob = viterbi_table[t-1][s_prime] * self.transition_probabilities[s_prime][s] * self.emission_probabilities[s][obs[t]]\n",
    "                        if prob > max_prob:\n",
    "                            max_prob = prob\n",
    "                            max_backpointer = s_prime\n",
    "\n",
    "                    viterbi_table[t][s] = max_prob\n",
    "                    backpointer[t][s] = max_backpointer\n",
    "\n",
    "        best_path_prob = max(viterbi_table[-1])\n",
    "        best_path_pointer = max(range(len(self.states)), key=lambda s: viterbi_table[-1][s])\n",
    "        best_path = [best_path_pointer]\n",
    "        for t in range(len(obs)-1, 0, -1):\n",
    "            best_path.insert(0, backpointer[t][best_path[0]])\n",
    "\n",
    "        return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_data(sequences, threshold):\n",
    "    word_counts = defaultdict(int)\n",
    "    for sequence in sequences:\n",
    "        for token, state in sequence:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    unk_sequences = []\n",
    "    for sequence in sequences:\n",
    "        unk_sequence = [(token if word_counts[token] > threshold else 'UNK', state) for token, state in sequence]\n",
    "        unk_sequences.append(unk_sequence)\n",
    "\n",
    "    return unk_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./cleaned_data.csv')\n",
    "test = pd.read_csv('./test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./cleaned_data.csv', converters={'tokens': ast.literal_eval, 'ner_tags': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(row['tokens'], row['ner_tags']) for _, row in df_train.iterrows()]\n",
    "unique_tags = set(tag for _, tags in train_data for tag in tags)\n",
    "states = list(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hmm_data = [list(zip(tokens, tags)) for tokens, tags in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_sequences = threshold_data(train_hmm_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('பைரவருக்கு', 1), ('தேய்பிறை', 0), ('UNK', 0), ('விசேஷ', 0), ('அபிஷேக', 0), ('ஆராதனைகள்', 0), ('நடைபெறுகின்றன', 0), ('.', 0)]\n"
     ]
    }
   ],
   "source": [
    "print(unk_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = set()\n",
    "for sequence in unk_sequences:\n",
    "    for token, _ in sequence:\n",
    "        unique_tokens.add(token)\n",
    "\n",
    "unique_tokens_list = list(unique_tokens)\n",
    "num_observations = len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmm(hmm_model, sequences):\n",
    "    hmm_model.compute_start_probabilities(sequences)\n",
    "    hmm_model.compute_transition_probabilities(sequences)\n",
    "    hmm_model.compute_emission_probabilities(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Probabilities:\n",
      "[0.69395158 0.09176672 0.         0.09568934 0.         0.11859236\n",
      " 0.        ]\n",
      "Transition Probabilities:\n",
      "[[8.70181685e-01 5.31512551e-02 0.00000000e+00 2.83013819e-02\n",
      "  0.00000000e+00 4.83656784e-02 0.00000000e+00]\n",
      " [4.73991545e-01 1.63788780e-02 5.01533281e-01 2.76563731e-03\n",
      "  2.04198610e-04 5.05839364e-03 6.80662033e-05]\n",
      " [6.36743036e-01 1.79804199e-02 3.28184296e-01 6.25756964e-03\n",
      "  1.48869600e-03 9.11384740e-03 2.32135648e-04]\n",
      " [4.62780528e-01 2.87547003e-03 8.33716162e-04 7.54314623e-03\n",
      "  5.23182414e-01 2.47279079e-03 3.11934619e-04]\n",
      " [3.55764544e-01 3.81564228e-03 5.19892865e-04 1.56756983e-02\n",
      "  6.16588296e-01 7.53844654e-03 9.74799122e-05]\n",
      " [7.78107609e-01 4.52930923e-03 5.06903367e-04 1.01672416e-02\n",
      "  2.63298008e-03 3.22339487e-02 1.71822008e-01]\n",
      " [5.34096742e-01 3.86969398e-03 5.92300099e-04 6.50213886e-03\n",
      "  1.68476473e-03 3.81309641e-02 4.15123396e-01]]\n",
      "Emission Probabilities:\n",
      "[[4.67347989e-06 1.27458543e-06 8.49723617e-07 ... 0.00000000e+00\n",
      "  8.28480526e-06 2.76160175e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.77209447e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.81351412e-05\n",
      "  4.86679580e-06 4.86679580e-06]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.76772141e-05 4.41930352e-06]\n",
      " [0.00000000e+00 0.00000000e+00 1.06677287e-05 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "hmm_model = HMM(states, unique_tokens_list)\n",
    "\n",
    "train_hmm(hmm_model, unk_sequences)\n",
    "\n",
    "print(\"Start Probabilities:\")\n",
    "print(hmm_model.start_probabilities)\n",
    "print(\"Transition Probabilities:\")\n",
    "print(hmm_model.transition_probabilities)\n",
    "print(\"Emission Probabilities:\")\n",
    "print(hmm_model.emission_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8650293870696893\n",
      "UNK Accuracy: 0.7225312934631433\n"
     ]
    }
   ],
   "source": [
    "test_tokens = test['tokens']\n",
    "test_ner_tags = test['ner_tags']\n",
    "misvals = []\n",
    "\n",
    "N_test = len(test_tokens)\n",
    "\n",
    "def compute_accuracy(hmm_model):\n",
    "    count_correct_new = 0\n",
    "    tot_new = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for idx in range(N_test):\n",
    "        tags = eval(test_ner_tags[idx])\n",
    "        observations = [obs for obs in eval(test_tokens[idx])]\n",
    "        if(len(observations)==0):\n",
    "            continue\n",
    "        observed_tokens = [tok for tok in eval(test_ner_tags[idx])]\n",
    "        observation_indices = [hmm_model.observation_index[obs] if obs in hmm_model.observation_index else hmm_model.observation_index['UNK'] for obs in observations]\n",
    "        predicted_tags = hmm_model.viterbi_algorithm(observation_indices)\n",
    "        for i,obs in enumerate(observations):\n",
    "            if obs not in hmm_model.observation_index:\n",
    "                tot_new += 1 \n",
    "                if(predicted_tags[i] == tags[i]):\n",
    "                    count_correct_new += 1\n",
    "\n",
    "        for i in range(len(predicted_tags)):\n",
    "            if(predicted_tags[i] == observed_tokens[i]):\n",
    "                correct += 1\n",
    "        total += len(observations)\n",
    "    return correct / total, count_correct_new / tot_new\n",
    "\n",
    "\n",
    "accuracy, unk_accuracy = compute_accuracy(hmm_model)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"UNK Accuracy:\", unk_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
