{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, states, observations):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.start_probabilities = np.zeros(len(states))\n",
    "        self.transition_probabilities = np.zeros((len(states), len(states)))\n",
    "        self.emission_probabilities = np.zeros((len(states), len(observations)))\n",
    "\n",
    "        self.state_index = {state: i for i, state in enumerate(states)}\n",
    "        self.observation_index = {obs: i for i, obs in enumerate(observations)}\n",
    "\n",
    "    def compute_start_probabilities(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            start_state = sequence[0][1]  # The tag of the first token\n",
    "            self.start_probabilities[self.state_index[start_state]] += 1\n",
    "        self.start_probabilities /= np.sum(self.start_probabilities)\n",
    "\n",
    "    def compute_transition_probabilities(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            for i in range(len(sequence) - 1):\n",
    "                current_state = sequence[i][1]\n",
    "                next_state = sequence[i + 1][1]\n",
    "                self.transition_probabilities[self.state_index[current_state], self.state_index[next_state]] += 1\n",
    "\n",
    "        for i in range(len(self.states)):\n",
    "            if(np.sum(self.transition_probabilities[i])==0):\n",
    "                continue\n",
    "            self.transition_probabilities[i] /= np.sum(self.transition_probabilities[i])\n",
    "\n",
    "    def compute_emission_probabilities(self, sequences):\n",
    "        for sequence in sequences:\n",
    "            for token, state in sequence:\n",
    "                self.emission_probabilities[self.state_index[state], self.observation_index[token]] += 1\n",
    "\n",
    "        for i in range(len(self.states)):\n",
    "            if(np.sum(self.emission_probabilities[i])==0):\n",
    "                continue\n",
    "            self.emission_probabilities[i] /= np.sum(self.emission_probabilities[i])\n",
    "\n",
    "    def viterbi_algorithm(self, obs):\n",
    "        viterbi_table = [[0.0 for _ in range(len(self.states))] for _ in range(len(obs))]\n",
    "        backpointer = [[0 for _ in range(len(self.states))] for _ in range(len(obs))]\n",
    "\n",
    "        for t in range(len(obs)):\n",
    "            for s in range(len(self.states)):\n",
    "                if t == 0:\n",
    "                    viterbi_table[t][s] = self.start_probabilities[s] * self.emission_probabilities[s][obs[t]]\n",
    "                else:\n",
    "                    max_prob = -1\n",
    "                    max_backpointer = -1\n",
    "\n",
    "                    for s_prime in range(len(self.states)):\n",
    "                        prob = viterbi_table[t-1][s_prime] * self.transition_probabilities[s_prime][s] * self.emission_probabilities[s][obs[t]]\n",
    "                        if prob > max_prob:\n",
    "                            max_prob = prob\n",
    "                            max_backpointer = s_prime\n",
    "\n",
    "                    viterbi_table[t][s] = max_prob\n",
    "                    backpointer[t][s] = max_backpointer\n",
    "\n",
    "        best_path_prob = max(viterbi_table[-1])\n",
    "        best_path_pointer = max(range(len(self.states)), key=lambda s: viterbi_table[-1][s])\n",
    "        best_path = [best_path_pointer]\n",
    "        for t in range(len(obs)-1, 0, -1):\n",
    "            best_path.insert(0, backpointer[t][best_path[0]])\n",
    "\n",
    "        return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_data(sequences, threshold):\n",
    "    word_counts = defaultdict(int)\n",
    "    for sequence in sequences:\n",
    "        for token, state in sequence:\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    unk_sequences = []\n",
    "    for sequence in sequences:\n",
    "        unk_sequence = [(token if word_counts[token] > threshold else 'UNK', state) for token, state in sequence]\n",
    "        unk_sequences.append(unk_sequence)\n",
    "\n",
    "    return unk_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./gujarati_train_data.csv')\n",
    "test = pd.read_csv('./gujarati_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./gujarati_train_data.csv', converters={'tokens': ast.literal_eval, 'ner_tags': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(row['tokens'], row['ner_tags']) for _, row in df_train.iterrows()]\n",
    "unique_tags = set(tag for _, tags in train_data for tag in tags)\n",
    "states = list(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hmm_data = [list(zip(tokens, tags)) for tokens, tags in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_sequences = threshold_data(train_hmm_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('લક્ઝરી', 0), ('સેન્ટ', 5), ('એન્ડ્રુ', 6), ('માતાનો', 6), ('ચર્ચ', 6)]\n"
     ]
    }
   ],
   "source": [
    "print(unk_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = set()\n",
    "for sequence in unk_sequences:\n",
    "    for token, _ in sequence:\n",
    "        unique_tokens.add(token)\n",
    "\n",
    "unique_tokens_list = list(unique_tokens)\n",
    "num_observations = len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmm(hmm_model, sequences):\n",
    "    hmm_model.compute_start_probabilities(sequences)\n",
    "    hmm_model.compute_transition_probabilities(sequences)\n",
    "    hmm_model.compute_emission_probabilities(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Probabilities:\n",
      "[0.64992968 0.12283941 0.         0.10794658 0.         0.11928433\n",
      " 0.        ]\n",
      "Transition Probabilities:\n",
      "[[8.79156890e-01 5.51401080e-02 0.00000000e+00 3.07241538e-02\n",
      "  0.00000000e+00 3.49788483e-02 0.00000000e+00]\n",
      " [2.71415376e-01 1.55862047e-02 6.99710381e-01 4.89691125e-03\n",
      "  2.37957324e-04 8.09054902e-03 6.26203485e-05]\n",
      " [7.20740567e-01 2.38400692e-02 2.16323703e-01 1.48377306e-02\n",
      "  1.26457932e-03 2.27147769e-02 2.78573994e-04]\n",
      " [5.60108715e-01 7.21998719e-03 1.00209707e-03 1.19909469e-02\n",
      "  4.12453378e-01 7.06845056e-03 1.56424909e-04]\n",
      " [3.91808060e-01 6.72594495e-03 5.60495413e-04 2.13695678e-02\n",
      "  5.69909559e-01 9.41958795e-03 2.06784715e-04]\n",
      " [7.69289858e-01 8.93353535e-03 8.44547997e-04 1.83423942e-02\n",
      "  2.10924801e-03 4.44809425e-02 1.55999474e-01]\n",
      " [5.62097000e-01 9.27016167e-03 7.84973367e-04 1.46154565e-02\n",
      "  1.71946547e-03 5.13223063e-02 3.60190636e-01]]\n",
      "Emission Probabilities:\n",
      "[[1.21865641e-06 1.42176581e-06 2.43731282e-06 ... 2.03109402e-07\n",
      "  0.00000000e+00 2.03109402e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.79786368e-05 1.55436871e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 3.53303208e-06]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.09956119e-05\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "hmm_model = HMM(states, unique_tokens_list)\n",
    "\n",
    "train_hmm(hmm_model, unk_sequences)\n",
    "\n",
    "print(\"Start Probabilities:\")\n",
    "print(hmm_model.start_probabilities)\n",
    "print(\"Transition Probabilities:\")\n",
    "print(hmm_model.transition_probabilities)\n",
    "print(\"Emission Probabilities:\")\n",
    "print(hmm_model.emission_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8982154659616656\n",
      "UNK Accuracy: 0.6525911708253359\n"
     ]
    }
   ],
   "source": [
    "test_tokens = test['tokens']\n",
    "test_ner_tags = test['ner_tags']\n",
    "misvals = []\n",
    "\n",
    "N_test = len(test_tokens)\n",
    "\n",
    "def compute_accuracy(hmm_model):\n",
    "    count_correct_new = 0\n",
    "    tot_new = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for idx in range(N_test):\n",
    "        tags = eval(test_ner_tags[idx])\n",
    "        observations = [obs for obs in eval(test_tokens[idx])]\n",
    "        if(len(observations)==0):\n",
    "            continue\n",
    "        observed_tokens = [tok for tok in eval(test_ner_tags[idx])]\n",
    "        observation_indices = [hmm_model.observation_index[obs] if obs in hmm_model.observation_index else hmm_model.observation_index['UNK'] for obs in observations]\n",
    "        predicted_tags = hmm_model.viterbi_algorithm(observation_indices)\n",
    "        for i,obs in enumerate(observations):\n",
    "            if obs not in hmm_model.observation_index:\n",
    "                tot_new += 1 \n",
    "                if(predicted_tags[i] == tags[i]):\n",
    "                    count_correct_new += 1\n",
    "\n",
    "        for i in range(len(predicted_tags)):\n",
    "            if(predicted_tags[i] == observed_tokens[i]):\n",
    "                correct += 1\n",
    "        total += len(observations)\n",
    "    return correct / total, count_correct_new / tot_new\n",
    "\n",
    "\n",
    "accuracy, unk_accuracy = compute_accuracy(hmm_model)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"UNK Accuracy:\", unk_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
